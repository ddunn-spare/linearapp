---
phase: 01-approval-infrastructure-flow
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/shared/src/index.ts
  - apps/server/src/db.ts
  - apps/server/src/services/actionStateMachine.ts
  - apps/server/src/services/chatService.ts
  - apps/server/src/routes/chat.ts
  - apps/server/src/adapters/openaiClient.ts
autonomous: true

must_haves:
  truths:
    - "Action proposals have a typed lifecycle with states: proposed, approved, declined, executing, succeeded, failed"
    - "Action proposals persist in the database and survive page refresh"
    - "SSE sends events incrementally to the client during OpenAI processing (not collect-then-flush)"
    - "New SSE event types exist for action_proposed, action_update lifecycle events"
  artifacts:
    - path: "packages/shared/src/index.ts"
      provides: "ActionProposal, ActionState, ActionPreviewField types and new ChatStreamEvent variants"
      contains: "ActionState"
    - path: "apps/server/src/db.ts"
      provides: "action_proposals table with CRUD methods"
      contains: "action_proposals"
    - path: "apps/server/src/services/actionStateMachine.ts"
      provides: "ActionStateMachine class with state transitions and idempotency guards"
      exports: ["ActionStateMachine"]
    - path: "apps/server/src/services/chatService.ts"
      provides: "Streaming chat with async generator and action proposal awareness"
      contains: "chatStream"
    - path: "apps/server/src/routes/chat.ts"
      provides: "True SSE streaming endpoint that writes events incrementally"
      contains: "chatStream"
  key_links:
    - from: "apps/server/src/services/chatService.ts"
      to: "apps/server/src/adapters/openaiClient.ts"
      via: "chatStream async generator"
      pattern: "openai\\.chatStream"
    - from: "apps/server/src/services/actionStateMachine.ts"
      to: "apps/server/src/db.ts"
      via: "database persistence of action state"
      pattern: "db\\.(createActionProposal|updateActionState)"
    - from: "apps/server/src/routes/chat.ts"
      to: "apps/server/src/services/chatService.ts"
      via: "async generator yielding SSE events"
      pattern: "for await.*handleMessageStream"
---

<objective>
Create the foundational types, database schema, state machine, and SSE streaming infrastructure for the approval flow.

Purpose: This plan establishes the data model, persistence, and real-time streaming that all subsequent approval flow plans build on. Without typed action proposals, persistent state, and true SSE streaming, the approval cards and execution flow cannot function.

Output: Shared types for actions, a new database table for action proposals, an ActionStateMachine service with idempotency, and a refactored chat service + route that streams events incrementally via SSE.
</objective>

<execution_context>
@/Users/devondunn/.claude/get-shit-done/workflows/execute-plan.md
@/Users/devondunn/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-approval-infrastructure-flow/01-CONTEXT.md
@packages/shared/src/index.ts
@apps/server/src/db.ts
@apps/server/src/services/chatService.ts
@apps/server/src/routes/chat.ts
@apps/server/src/adapters/openaiClient.ts
@apps/server/src/app.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add action proposal types to shared package and create DB schema</name>
  <files>
    packages/shared/src/index.ts
    apps/server/src/db.ts
  </files>
  <action>
**In `packages/shared/src/index.ts`**, add after the existing Chat section:

1. `ActionState` type — union of `"proposed" | "approved" | "declined" | "executing" | "succeeded" | "failed"`

2. `ActionPreviewField` type — `{ field: string; oldValue?: string; newValue: string }` — represents one line of the diff-style preview (per user decision: "full diff-style detail, field by field, like a data diff")

3. `ActionProposal` type:
   - `id: string` — UUID
   - `conversationId: string`
   - `messageId: string` — the assistant message this proposal belongs to
   - `toolName: string` — which tool will execute
   - `toolArguments: Record<string, unknown>` — parsed args for the tool
   - `description: string` — plain-language description of what will change (APPR-02)
   - `preview: ActionPreviewField[]` — diff-style field changes
   - `state: ActionState`
   - `idempotencyKey: string` — for duplicate execution prevention (INFRA-05)
   - `result?: string` — execution result (success message or error)
   - `resultUrl?: string` — link to created/modified resource (for success collapse)
   - `error?: string` — plain-language error on failure (APPR-05)
   - `createdAt: string`
   - `updatedAt: string`

4. Extend `ChatStreamEvent` union with new variants:
   - `| { type: "action_proposed"; proposal: ActionProposal }` — agent proposes an action
   - `| { type: "action_update"; proposalId: string; state: ActionState; result?: string; resultUrl?: string; error?: string }` — lifecycle state change

5. Add `ActionProposal` to the `ChatMessage` type: `actionProposals?: ActionProposal[]`

**In `apps/server/src/db.ts`**:

1. Add `action_proposals` table to the schema SQL:
   ```sql
   CREATE TABLE IF NOT EXISTS action_proposals (
     id TEXT PRIMARY KEY,
     conversation_id TEXT NOT NULL REFERENCES chat_conversations(id) ON DELETE CASCADE,
     message_id TEXT NOT NULL,
     tool_name TEXT NOT NULL,
     tool_arguments_json TEXT NOT NULL,
     description TEXT NOT NULL,
     preview_json TEXT NOT NULL,
     state TEXT NOT NULL DEFAULT 'proposed',
     idempotency_key TEXT NOT NULL UNIQUE,
     result TEXT,
     result_url TEXT,
     error TEXT,
     created_at TEXT NOT NULL,
     updated_at TEXT NOT NULL
   );
   ```
   The `idempotency_key` UNIQUE constraint is the first line of defense against duplicate execution.

2. Add methods to `StateDb` class:
   - `createActionProposal(proposal: ActionProposal): void` — INSERT with JSON serialization of toolArguments and preview
   - `updateActionState(id: string, state: ActionState, updates?: { result?: string; resultUrl?: string; error?: string }): void` — UPDATE state and optional result fields, set updated_at
   - `getActionProposal(id: string): ActionProposal | null` — SELECT by id, deserialize JSON fields
   - `getActionProposalsByMessage(messageId: string): ActionProposal[]` — SELECT by message_id for re-rendering on refresh (INFRA-04)
   - `getActionProposalsByConversation(conversationId: string): ActionProposal[]` — SELECT by conversation_id
   - `getActionProposalByIdempotencyKey(key: string): ActionProposal | null` — SELECT by idempotency_key for dedup checks

   Follow existing db.ts patterns: use `.prepare().run()` / `.prepare().get()` / `.prepare().all()`, map snake_case columns to camelCase properties. Parse JSON fields with `JSON.parse()`.
  </action>
  <verify>
Run `npx tsc --noEmit` from the repo root to confirm no type errors. Verify the shared package builds: `cd packages/shared && npx tsc --noEmit`. Verify server compiles: `cd apps/server && npx tsc --noEmit`.
  </verify>
  <done>
ActionProposal type and ActionState enum exist in shared package. The action_proposals table is created in the DB schema. All CRUD methods exist on StateDb and compile without errors. ChatStreamEvent includes action_proposed and action_update variants.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create ActionStateMachine service with idempotency guards</name>
  <files>
    apps/server/src/services/actionStateMachine.ts
  </files>
  <action>
Create `apps/server/src/services/actionStateMachine.ts` exporting an `ActionStateMachine` class.

**Constructor:** Takes `StateDb` instance.

**State transition rules** (enforce these strictly):
- `proposed` -> `approved` | `declined`
- `approved` -> `executing`
- `executing` -> `succeeded` | `failed`
- `failed` -> `executing` (retry)
- Terminal states: `succeeded`, `declined` (no further transitions)

**Methods:**

1. `createProposal(params: { conversationId, messageId, toolName, toolArguments, description, preview }): ActionProposal`
   - Generate UUID for id
   - Generate idempotency key: `${conversationId}:${toolName}:${JSON.stringify(toolArguments)}:${Date.now()}` — include timestamp so the same logical action can be proposed multiple times in different messages (but the same proposal cannot be executed twice)
   - Set state to "proposed"
   - Persist via `db.createActionProposal()`
   - Return the created proposal

2. `approve(proposalId: string): ActionProposal`
   - Load proposal from DB
   - If state is not "proposed", throw error (invalid transition)
   - Update state to "approved"
   - Return updated proposal

3. `decline(proposalId: string): ActionProposal`
   - Load proposal from DB
   - If state is not "proposed", throw error
   - Update state to "declined"
   - Return updated proposal

4. `markExecuting(proposalId: string): ActionProposal`
   - Load proposal from DB
   - **Idempotency check (INFRA-05):** If state is already "executing" or "succeeded", return the existing proposal without error (idempotent — handles double-click)
   - If state is not "approved" and not "failed" (retry case), throw error
   - Update state to "executing"
   - Return updated proposal

5. `markSucceeded(proposalId: string, result: string, resultUrl?: string): ActionProposal`
   - Load proposal, verify state is "executing"
   - Update state to "succeeded" with result and resultUrl
   - Return updated proposal

6. `markFailed(proposalId: string, error: string): ActionProposal`
   - Load proposal, verify state is "executing"
   - Update state to "failed" with error
   - Return updated proposal

7. `getProposal(proposalId: string): ActionProposal | null`
   - Delegate to `db.getActionProposal()`

8. `getProposalsByMessage(messageId: string): ActionProposal[]`
   - Delegate to `db.getActionProposalsByMessage()`

**Private helper:** `transition(proposalId: string, expectedStates: ActionState[], newState: ActionState, updates?): ActionProposal`
   - Load from DB, check current state is in expectedStates, update, return
   - Throws descriptive error if transition is invalid (e.g., "Cannot approve action in state 'succeeded'")

Follow codebase conventions: use `createLogger("ActionStateMachine")` for logging, TypeScript strict mode, explicit return types.
  </action>
  <verify>
Run `cd apps/server && npx tsc --noEmit`. The ActionStateMachine class should compile. Verify the file exports the class and can be imported from other server modules.
  </verify>
  <done>
ActionStateMachine class exists with all state transition methods. Idempotency guard in markExecuting prevents double-execution. Invalid state transitions throw descriptive errors. All methods persist changes to the database.
  </done>
</task>

<task type="auto">
  <name>Task 3: Refactor chat service and route to true SSE streaming</name>
  <files>
    apps/server/src/services/chatService.ts
    apps/server/src/routes/chat.ts
    apps/server/src/adapters/openaiClient.ts
  </files>
  <action>
**Current problem (INFRA-01):** The chat service collects ALL events into an array, returns them, and the route flushes them all at once. This is not true SSE streaming — the client sees nothing until the entire LLM response is complete.

**Refactor chatService.ts to use async generator:**

1. Add a new method `async *handleMessageStream(conversationId: string, userMessage: string): AsyncGenerator<ChatStreamEvent>`:
   - Same conversation/message creation logic as existing `handleMessage()`
   - Build message history the same way
   - In the function-calling loop, use `this.openai.chatStream()` (already exists in openaiClient.ts) instead of `this.openai.chat()`
   - Process the streaming chunks:
     - Accumulate content deltas and `yield { type: "delta", content: chunk.choices[0].delta.content }` for each non-empty content delta
     - Accumulate tool_calls from streaming chunks (they arrive incrementally: first chunk has function name, subsequent chunks have argument fragments)
     - When a tool call is complete (detected by receiving a new tool_call index or stream finish), `yield { type: "tool_call_start", ... }` then execute the tool handler, then `yield { type: "tool_call_result", ... }`
   - After the final iteration, save the assistant message to DB
   - `yield { type: "done", messageId }` at the end

   **Important:** The existing `chatStream()` method in openaiClient.ts already returns `AsyncGenerator<ChatCompletionChunk>`. Use it. Each chunk has `choices[0].delta` with optional `content`, `tool_calls` (with index, function name fragments, argument fragments).

   **Streaming tool call accumulation pattern:**
   ```typescript
   // Accumulate tool calls from stream chunks
   const pendingToolCalls: Map<number, { id: string; name: string; arguments: string }> = new Map();

   for await (const chunk of this.openai.chatStream(messages, tools)) {
     const delta = chunk.choices[0]?.delta;
     if (!delta) continue;

     // Content streaming
     if (delta.content) {
       fullContent += delta.content;
       yield { type: "delta", content: delta.content };
     }

     // Tool call accumulation
     if (delta.tool_calls) {
       for (const tc of delta.tool_calls) {
         const existing = pendingToolCalls.get(tc.index);
         if (!existing) {
           pendingToolCalls.set(tc.index, { id: tc.id || "", name: tc.function?.name || "", arguments: tc.function?.arguments || "" });
         } else {
           if (tc.id) existing.id = tc.id;
           if (tc.function?.name) existing.name += tc.function.name;
           if (tc.function?.arguments) existing.arguments += tc.function.arguments;
         }
       }
     }

     // Check finish_reason
     if (chunk.choices[0]?.finish_reason === "tool_calls" || chunk.choices[0]?.finish_reason === "stop") {
       break; // Process accumulated tool calls after loop
     }
   }
   ```

2. Keep the existing `handleMessage()` method as-is for backward compatibility (non-streaming callers), but mark it with a comment that it's deprecated in favor of `handleMessageStream()`.

**Refactor routes/chat.ts POST `/api/chat` handler:**

Replace the collect-then-flush pattern with true streaming:

```typescript
app.post("/api/chat", async (request, reply) => {
  // ... existing validation ...

  reply.raw.writeHead(200, {
    "Content-Type": "text/event-stream",
    "Cache-Control": "no-cache",
    Connection: "keep-alive",
    "Access-Control-Allow-Origin": "*",
  });

  try {
    for await (const event of chatService.handleMessageStream(conversationId, message)) {
      reply.raw.write(`data: ${JSON.stringify(event)}\n\n`);
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : "Chat failed";
    reply.raw.write(`data: ${JSON.stringify({ type: "error", error: errorMsg })}\n\n`);
  }

  reply.raw.end();
});
```

**No changes needed to openaiClient.ts** — the `chatStream()` method already exists and works.

**Ensure the streaming refactor preserves existing behavior:** All current SSE event types (delta, tool_call_start, tool_call_result, done, error) must still be emitted in the same order. The only change is WHEN they are emitted (incrementally vs. all-at-once).
  </action>
  <verify>
1. Run `cd apps/server && npx tsc --noEmit` — no type errors
2. Start the dev server (`npm run dev` from root) and open the chat page
3. Send a message that triggers a tool call (e.g., "Who is overloaded?") and verify:
   - Text appears incrementally (word by word) — not all at once after tool calls complete
   - Tool call chips still appear and resolve
   - Final message is saved correctly
4. Send a simple message (no tool calls) and verify text streams normally
  </verify>
  <done>
Chat service uses async generator with true SSE streaming. Events are emitted incrementally as OpenAI streams chunks. Tool calls are accumulated from stream fragments and executed when complete. The chat route writes events to the SSE connection as they are yielded. Existing functionality (tool calls, message persistence) is preserved.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes from repo root (all packages compile)
2. ActionProposal type is importable from `@linearapp/shared` in both server and web packages
3. action_proposals table is created when server starts (check with SQLite inspector or `SELECT * FROM action_proposals`)
4. ActionStateMachine correctly prevents invalid state transitions (proposed->executing should throw, proposed->approved should work)
5. Chat SSE streaming is truly incremental — text appears word-by-word in the browser, not in a single flush
6. Existing chat functionality (tool calls, conversation history, message persistence) still works correctly after the streaming refactor
</verification>

<success_criteria>
- Shared types for ActionProposal, ActionState, and new ChatStreamEvent variants exist and compile
- Database has action_proposals table with CRUD methods
- ActionStateMachine enforces valid state transitions and prevents duplicate execution via idempotency
- Chat service streams events incrementally via async generator (INFRA-01)
- All existing chat features continue to work (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/01-approval-infrastructure-flow/01-01-SUMMARY.md`
</output>
